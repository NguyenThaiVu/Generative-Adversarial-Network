{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Deep Convolutional GAN.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"13TiUb5jUF-n4Ke-CeEgx8sof4w4i8cU7","authorship_tag":"ABX9TyPDtBnQrCytjQM96s6YEmgG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"b0PaJ-g4-5GI"},"source":["# Set up "]},{"cell_type":"code","metadata":{"id":"A12ijBdR7h5G","executionInfo":{"status":"ok","timestamp":1625566771567,"user_tz":-420,"elapsed":356356,"user":{"displayName":"Vũ Nguyễn Thái","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gibo23x78nzU8U0Hl95G0sBjdvzzNTmI98CIlHR=s64","userId":"18002931970831166896"}}},"source":["# !cp -r \"/content/drive/MyDrive/AffectNet data/AffectNet.h5\" /content/AffectNet.h5\n","# # !cp -r \"/content/drive/MyDrive/AffectNet data/balance_affectNet.h5\" /content/AffectNet.h5"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"_8fAOGfI9eJi","executionInfo":{"status":"ok","timestamp":1625566776862,"user_tz":-420,"elapsed":5298,"user":{"displayName":"Vũ Nguyễn Thái","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gibo23x78nzU8U0Hl95G0sBjdvzzNTmI98CIlHR=s64","userId":"18002931970831166896"}}},"source":["import os\n","import numpy as np\n","import h5py\n","import cv2\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import *"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V1jzKbOGBcbI","executionInfo":{"status":"ok","timestamp":1625567050078,"user_tz":-420,"elapsed":273226,"user":{"displayName":"Vũ Nguyễn Thái","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gibo23x78nzU8U0Hl95G0sBjdvzzNTmI98CIlHR=s64","userId":"18002931970831166896"}},"outputId":"bb60a803-1737-4697-848a-c6766e941ed9"},"source":["hf = h5py.File('AffectNet.h5', 'r')\n","images = hf['images'][:]\n","hf.close()\n","\n","print(images.shape)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["(414798, 112, 112, 3)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aLidjb9h-6nX"},"source":["# Define architecture of Deep Convolutional GAN"]},{"cell_type":"code","metadata":{"id":"Mooc0o-9-2J9","executionInfo":{"status":"ok","timestamp":1625567050079,"user_tz":-420,"elapsed":5,"user":{"displayName":"Vũ Nguyễn Thái","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gibo23x78nzU8U0Hl95G0sBjdvzzNTmI98CIlHR=s64","userId":"18002931970831166896"}}},"source":["class DCGAN:\n","\n","    @staticmethod\n","    def build_generator(dim, depth, channels=3, inputDim=100, outputDim=512):\n","\n","        model = Sequential()\n","        inputShape = (dim, dim, depth)\n","        chanDim = -1\n","\n","        model.add(Dense(input_dim=inputDim, units=outputDim))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization())\n","\n","        model.add(Dense(dim * dim * depth))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization())\n","\n","        model.add(Reshape(inputShape))  # (4, 4, 1024)\n","\n","        model.add(Conv2DTranspose(512, (4, 4), strides=(2, 2), padding=\"same\")) # (8, 8, 512)\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\n","\n","        model.add(Conv2DTranspose(256, (4, 4), strides=(2, 2), padding=\"same\")) # (16, 16, 256)\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\n","\n","        model.add(Conv2DTranspose(125, (4, 4), strides=(2, 2), padding=\"same\")) # (32, 32, 128)\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\n","\n","        model.add(Conv2DTranspose(channels, (4, 4), strides=(2, 2), padding=\"same\"))\n","        model.add(Activation(\"tanh\"))\n","        \n","        return model\n","\n","    @staticmethod\n","    def build_discriminator(width, height, depth, alpha=0.2):\n","\n","        model = Sequential()\n","\n","        inputShape = (height, width, depth)\n","\n","        model.add(Conv2D(128, (4, 4), padding=\"same\", strides=(2, 2), input_shape=inputShape))\n","        model.add(LeakyReLU(alpha=alpha))\n","\n","        model.add(Conv2D(256, (4, 4), padding=\"same\", strides=(2, 2)))\n","        model.add(LeakyReLU(alpha=alpha))\n","\n","        model.add(Conv2D(512, (4, 4), padding=\"same\", strides=(2, 2)))\n","        model.add(LeakyReLU(alpha=alpha))\n","\n","        model.add(Conv2D(1024, (4, 4), padding=\"same\", strides=(2, 2)))\n","        model.add(LeakyReLU(alpha=alpha))\n","\n","        model.add(Flatten())\n","        model.add(Dense(512))\n","        model.add(LeakyReLU(alpha=alpha))\n","\n","        model.add(Dense(1))\n","        model.add(Activation(\"sigmoid\"))\n","\n","        return model"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NRCgNOVLBNQT","executionInfo":{"status":"ok","timestamp":1625567051511,"user_tz":-420,"elapsed":1436,"user":{"displayName":"Vũ Nguyễn Thái","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gibo23x78nzU8U0Hl95G0sBjdvzzNTmI98CIlHR=s64","userId":"18002931970831166896"}},"outputId":"af039ae2-3d60-4331-b416-24bcfc806513"},"source":["dcGan = DCGAN()\n","\n","gen = dcGan.build_generator(dim=4, depth=1024)\n","gen.summary()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense (Dense)                (None, 512)               51712     \n","_________________________________________________________________\n","activation (Activation)      (None, 512)               0         \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 512)               2048      \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 16384)             8404992   \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 16384)             0         \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 16384)             65536     \n","_________________________________________________________________\n","reshape (Reshape)            (None, 4, 4, 1024)        0         \n","_________________________________________________________________\n","conv2d_transpose (Conv2DTran (None, 8, 8, 512)         8389120   \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 8, 8, 512)         0         \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 8, 8, 512)         2048      \n","_________________________________________________________________\n","conv2d_transpose_1 (Conv2DTr (None, 16, 16, 256)       2097408   \n","_________________________________________________________________\n","activation_3 (Activation)    (None, 16, 16, 256)       0         \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 16, 16, 256)       1024      \n","_________________________________________________________________\n","conv2d_transpose_2 (Conv2DTr (None, 32, 32, 125)       512125    \n","_________________________________________________________________\n","activation_4 (Activation)    (None, 32, 32, 125)       0         \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 32, 32, 125)       500       \n","_________________________________________________________________\n","conv2d_transpose_3 (Conv2DTr (None, 64, 64, 3)         6003      \n","_________________________________________________________________\n","activation_5 (Activation)    (None, 64, 64, 3)         0         \n","=================================================================\n","Total params: 19,532,516\n","Trainable params: 19,496,938\n","Non-trainable params: 35,578\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jsnu9-KJBUtc","executionInfo":{"status":"ok","timestamp":1625567051512,"user_tz":-420,"elapsed":12,"user":{"displayName":"Vũ Nguyễn Thái","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gibo23x78nzU8U0Hl95G0sBjdvzzNTmI98CIlHR=s64","userId":"18002931970831166896"}},"outputId":"18eb01ec-200b-4727-d0d8-0fb7599bf9b3"},"source":["disc = dcGan.build_discriminator(width=64, height=64, depth=3)\n","disc.summary()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 32, 32, 128)       6272      \n","_________________________________________________________________\n","leaky_re_lu (LeakyReLU)      (None, 32, 32, 128)       0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 16, 16, 256)       524544    \n","_________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 256)       0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 8, 8, 512)         2097664   \n","_________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 512)         0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 4, 4, 1024)        8389632   \n","_________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 1024)        0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 16384)             0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 512)               8389120   \n","_________________________________________________________________\n","leaky_re_lu_4 (LeakyReLU)    (None, 512)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 1)                 513       \n","_________________________________________________________________\n","activation_6 (Activation)    (None, 1)                 0         \n","=================================================================\n","Total params: 19,407,745\n","Trainable params: 19,407,745\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_H-3xj8vLCeF"},"source":["# Prepare data"]},{"cell_type":"code","metadata":{"id":"hjzO0HbOLD10","executionInfo":{"status":"ok","timestamp":1625567051513,"user_tz":-420,"elapsed":7,"user":{"displayName":"Vũ Nguyễn Thái","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gibo23x78nzU8U0Hl95G0sBjdvzzNTmI98CIlHR=s64","userId":"18002931970831166896"}}},"source":["# Nomalize preprocessor \n","class NomalizePreprocessor:\n","    def __init__(self):\n","        pass\n","\n","    def preprocess(self, image):\n","        return (image.astype(\"float\") - 127.5) / 127.5"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"LlZ917PoLPa8","executionInfo":{"status":"ok","timestamp":1625567051514,"user_tz":-420,"elapsed":7,"user":{"displayName":"Vũ Nguyễn Thái","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gibo23x78nzU8U0Hl95G0sBjdvzzNTmI98CIlHR=s64","userId":"18002931970831166896"}}},"source":["# Nomalize preprocessor \n","class ResizePreprocessor:\n","    def __init__(self, new_size):\n","        self.new_size = new_size\n","\n","    def preprocess(self, image):\n","        return cv2.resize(image, self.new_size)"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YID6Ed5kF6MX"},"source":["# Training DC GAN"]},{"cell_type":"code","metadata":{"id":"ICgGlQHRByZw","executionInfo":{"status":"ok","timestamp":1625567051893,"user_tz":-420,"elapsed":386,"user":{"displayName":"Vũ Nguyễn Thái","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gibo23x78nzU8U0Hl95G0sBjdvzzNTmI98CIlHR=s64","userId":"18002931970831166896"}}},"source":["from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.datasets import fashion_mnist, mnist\n","from sklearn.utils import shuffle\n","from imutils import build_montages\n","import numpy as np\n","import argparse\n","import cv2\n","import os"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EaHvwuYVF7fQ","executionInfo":{"status":"ok","timestamp":1625567052374,"user_tz":-420,"elapsed":5,"user":{"displayName":"Vũ Nguyễn Thái","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gibo23x78nzU8U0Hl95G0sBjdvzzNTmI98CIlHR=s64","userId":"18002931970831166896"}},"outputId":"1e06e994-b7b8-41db-dc51-5712453452d5"},"source":["OUTPUT_PATH = \"output\"\n","NUM_EPOCHS = 30\n","BATCH_SIZE = 128\n","INIT_LR = 2e-4\n","\n","! mkdir \"output\""],"execution_count":10,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‘output’: File exists\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CQ8GgUrMGKMk","executionInfo":{"status":"ok","timestamp":1625567052757,"user_tz":-420,"elapsed":385,"user":{"displayName":"Vũ Nguyễn Thái","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gibo23x78nzU8U0Hl95G0sBjdvzzNTmI98CIlHR=s64","userId":"18002931970831166896"}}},"source":["# Build generator model\n","gen = DCGAN.build_generator(dim=4, depth=1024)\n","\n","# Build discriminator model\n","disc = DCGAN.build_discriminator(width=64, height=64, depth=3)\n","\n","discOpt = Adam(learning_rate=INIT_LR, beta_1=0.5, decay=INIT_LR / NUM_EPOCHS)\n","disc.compile(loss=\"binary_crossentropy\", optimizer=discOpt)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"5AaJa5RbGV4S","executionInfo":{"status":"ok","timestamp":1625567052757,"user_tz":-420,"elapsed":2,"user":{"displayName":"Vũ Nguyễn Thái","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gibo23x78nzU8U0Hl95G0sBjdvzzNTmI98CIlHR=s64","userId":"18002931970831166896"}}},"source":["# Build GAN\n","disc.trainable = False  # FREEZE PARAMETERE\n","ganInput = Input(shape=(100,))\n","ganOutput = disc(gen(ganInput))\n","gan = Model(ganInput, ganOutput)\n","\n","# compile the GAN\n","ganOpt = Adam(learning_rate=INIT_LR, beta_1=0.5, decay=INIT_LR / NUM_EPOCHS)\n","gan.compile(loss=\"binary_crossentropy\", optimizer=discOpt)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"OLnOo5wLLdnV","executionInfo":{"status":"ok","timestamp":1625567053146,"user_tz":-420,"elapsed":391,"user":{"displayName":"Vũ Nguyễn Thái","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gibo23x78nzU8U0Hl95G0sBjdvzzNTmI98CIlHR=s64","userId":"18002931970831166896"}}},"source":["normPro = NomalizePreprocessor()\n","resizePro = ResizePreprocessor(new_size=(64, 64))"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"kCHmimU4GYh2"},"source":["# Training process\n","benchmarkNoise = np.random.uniform(-1, 1, size=(64, 100))\n","\n","# loop over the epochs\n","for epoch in range(0, NUM_EPOCHS):\n","    print(\"[INFO] starting epoch {} of {}...\".format(epoch + 1, NUM_EPOCHS))\n","    batchesPerEpoch = int(images.shape[0] / BATCH_SIZE)\n","\n","    for i in range(0, batchesPerEpoch):\n","\n","        imageBatch = images[i * BATCH_SIZE:(i + 1) * BATCH_SIZE]\n","        # preprocess real images\n","        process_imageBatch = []\n","        for image in imageBatch:\n","            image = resizePro.preprocess(image)\n","            image = normPro.preprocess(image)\n","            process_imageBatch.append(image)\n","        imageBatch = np.array(process_imageBatch)\n","\n","        # Generator generate image\n","        noise = np.random.uniform(-1, 1, size=(BATCH_SIZE, 100))\n","        genImages = gen.predict(noise, verbose=0)\n","\n","        # Concat \"real\" images and \"'fake\" images\n","        X = np.concatenate((imageBatch, genImages))\n","        y = ([1] * BATCH_SIZE) + ([0] * BATCH_SIZE)\n","        y = np.reshape(y, (-1,))\n","        (X, y) = shuffle(X, y)\n","\n","        # train the discriminator on the data\n","        discLoss = disc.train_on_batch(X, y)\n","\n","        # Inverted label\n","        noise = np.random.uniform(-1, 1, (BATCH_SIZE, 100))\n","        fakeLabels = [1] * BATCH_SIZE\n","        fakeLabels = np.reshape(fakeLabels, (-1,))\n","        ganLoss = gan.train_on_batch(noise, fakeLabels)\n","\n","        # End of Epoch\n","        if i == batchesPerEpoch - 1:\n","\t\t\t\n","            p = [OUTPUT_PATH, \"epoch_{}_output.png\".format(str(epoch + 1).zfill(4))]\n","\n","            print(\"[INFO] Step {}_{}: discriminator_loss={:.6f}, \"\"adversarial_loss={:.6f}\".format(epoch + 1, i, discLoss, ganLoss))\n","\n","            # make predictions on the benchmark noise, scale it back to [0, 255], and generate the montage\n","            plotImages = gen.predict(benchmarkNoise)\n","            plotImages = ((plotImages * 127.5) + 127.5).astype(\"uint8\")\n","            vis = build_montages(plotImages, (64, 64), (8, 8))[0]\n","\n","            # write the visualization to disk\n","            p = os.path.sep.join(p)\n","            print(\"path: \", p)\n","            cv2.imwrite(p, vis)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C4ft3Jd1GZ-J"},"source":[""],"execution_count":null,"outputs":[]}]}